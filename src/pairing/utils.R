library(stringr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(tidyr, warn.conflicts = FALSE)
library(tibble, warn.conflicts = FALSE)
library(tsibble, warn.conflicts = FALSE)
library(sf, warn.conflicts = FALSE)
library(digest, warn.conflicts = FALSE)
library(stringdist, warn.conflicts = FALSE)

source("src/load/load.R")

prepare_metadata <- function(metadata, dem) {
    metadata |> mutate(dem = st_extract(dem, geometry) |> pull(1))
}

normalize_name <- function(string) {
    string |>
        str_to_lower() |>
        str_remove_all(regex("[^[:lower:]]")) |>
        str_squish()
}

#' The fraction of data, with respects to the shortest series (having excluded NAs), that is not NA. Series must be of the same length.
#'
#' @param s1 A time series.
#' @param s2 A time series.
minimal_overlap <- function(s1, s2) {
    sum(!(is.na(s1) | is.na(s2))) / min(length(s1 |> na.omit()), length(s2 |> na.omit()))
}

#' The fraction of data that is either missing in both series or present in both series. Series must be of the same length.
#'
#' @param s1 A time series.
#' @param s2 A time series.
overlap <- function(s1, s2) {
    1 - sum(xor(is.na(s1), is.na(s2))) / length(s1)
}

Tinfo <- function(details1, details2) {
    s1 <- do.call(read.series.single, details1) |>
        drop_na() |>
        fill_gaps() |>
        rename(T := details1[[2]])
    s2 <- do.call(read.series.single, details2) |>
        drop_na() |>
        fill_gaps() |>
        rename(T := details2[[2]])

    full_join(s1, s2, by = "date") |>
        as_tibble() |>
        summarise(
            delT = mean(abs(T.x - T.y), na.rm = TRUE),
            sdT = sd(abs(T.x - T.y), na.rm = TRUE),
            corT = cor(T.x, T.y, use = "na.or.complete"),
            overlap = overlap(T.x, T.y),
            minilap = minimal_overlap(T.x, T.y),
            valid_days.x = sum(!is.na(T.x)),
            valid_days.y = sum(!is.na(T.y)),
            valid_days_both = sum(!is.na(T.x) & !is.na(T.y)),
            first_date.x = min(s1$date),
            last_date.x = max(s1$date),
            first_date.y = min(s2$date),
            last_date.y = max(s2$date)
        )
}

add_distances <- function(match_table, m.db1, m.db2) {
    bind_cols(
        match_table,
        distance = st_distance(
            left_join(match_table |> st_drop_geometry(), m.db1, join_by(identifier.x == identifier)) |> st_as_sf(),
            left_join(match_table |> st_drop_geometry(), m.db2, join_by(identifier.y == identifier)) |> st_as_sf(),
            by_element = TRUE
        ) |> units::drop_units()
    )
}


#' Performs data cleanup on a match table removing duplicates. Assumes as input a "symmetric" match table (where each match is duplicated) as generated by st_join, with columns:
#' - identifier.x and .y;
#'
clean_match_table <- function(data) {
    is.same <- with(data, identifier.x == identifier.y)
    data |>
        subset(!is.same) |>
        mutate(digx_ = digest2int(as.character(identifier.x)), digy_ = digest2int(as.character(identifier.y)), digmin_ = pmin(digx_, digy_), digmax_ = pmax(digx_, digy_)) |> # WARNING: this is really bad practice, should not use mutate
        distinct(digmin_, digmax_, .keep_all = TRUE) |>
        select(!c(digx_, digy_, digmin_, digmax_)) |>
        bind_rows(subset(data, is.same))
}

analyze_match <- function(data, db1, db2, tvar, ...f = list(), ...s = list()) {
    data |>
        mutate(delH = elevation.x - elevation.y, delZ = dem.x - dem.y) |>
        mutate(strSym = stringsim(normalize_name(anagrafica.x), normalize_name(anagrafica.y), method = "jw")) |>
        rowwise() |>
        mutate(Tinfo = Tinfo(c(list(db1, tvar, identifier.x), ...f), c(list(db2, tvar, identifier.y), ...s))) |>
        unnest(Tinfo)
}

split_by <- function(data, ...) {

}
