{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from time import sleep\n",
    "from random import uniform\n",
    "from datetime import datetime, date\n",
    "\n",
    "base = Path.home() / \"Local_Workspace\" / \"Datasets\" / \"ARPA\" / \"MARCHE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {\"T\": \"TminMdmx\", \"X\": \"LonLat_Z\", \"rawT\": \"Temp_Val\"}\n",
    "\n",
    "\n",
    "def arpam_payload(\n",
    "    station_codes, from_date: datetime, to_date: datetime, variable, validated, sessid\n",
    "):\n",
    "    if type(station_codes) == str:\n",
    "        station_codes = [station_codes]\n",
    "    payload = {\n",
    "        \"sessid\": sessid,\n",
    "        \"outputType\": \"file\",\n",
    "        \"SelezionaStazione[]\": [f\"{code}\" for code in station_codes],\n",
    "        \"TipoDato\": \"validato\" if validated else \"originale\",\n",
    "        \"TipoTabella\": f\"{variables[variable]}\",\n",
    "        \"BeginDate\": from_date.strftime(r\"%Y-%m-%d+00:00\"),\n",
    "        \"EndDate\": to_date.strftime(r\"%Y-%m-%d+00:00\"),\n",
    "        \"LineNumberPdf\": \"0\",\n",
    "    }\n",
    "    if variable == \"T\":\n",
    "        payload[\"TimeStepType\"] = \"d\"\n",
    "        payload[\"TimeStep\"] = \"1\"\n",
    "    return payload\n",
    "\n",
    "\n",
    "def arpam_cookies(sessid):\n",
    "    return {\n",
    "        \"displayCookieConsent\": \"y\",\n",
    "        \"PHPSESSID\": sessid,\n",
    "    }\n",
    "\n",
    "\n",
    "def arpam_headers():\n",
    "    return {\n",
    "        \"Host\": \"app.protezionecivile.marche.it\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"it-IT,it;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "        \"Content-Length\": \"215\",\n",
    "        \"Origin\": \"http://app.protezionecivile.marche.it\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Referer\": \"http://app.protezionecivile.marche.it/sol/temperatura/menu.sol?lang=it\",\n",
    "        # \"Cookie\": f\"displayCookieConsent=y; displayCookieConsent=y; PHPSESSID={sessid}\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Pragma\": \"no-cache\",\n",
    "        \"Cache-Control\": \"no-cache\",\n",
    "    }\n",
    "\n",
    "\n",
    "def request_data(stat_number, sessid, from_date, to_date, variable, validated=True):\n",
    "    r = requests.post(\n",
    "        \"http://app.protezionecivile.marche.it/sol/temperatura/queryResultsFile.sol?lang=it\",\n",
    "        data=arpam_payload(\n",
    "            stat_number, from_date, to_date, variable, validated, sessid\n",
    "        ),\n",
    "        headers=arpam_headers(),\n",
    "        cookies=arpam_cookies(sessid),\n",
    "    )\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_page = BeautifulSoup((base / \"form.html\").read_text(), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_options(tag):\n",
    "    return tag.has_attr(\"data-multiselectid\") and tag[\"data-multiselectid\"].startswith(\n",
    "        \"multiselect_7qo2j7oogv7\"\n",
    "    )\n",
    "\n",
    "\n",
    "opts = form_page.find_all(station_options)\n",
    "station_numbers = [opt[\"value\"] for opt in opts]\n",
    "station_infos = [opt.text for opt in opts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "infos_pattern = re.compile(\n",
    "    r\"(?P<name>[^\\(]+) \\((?P<kind>R.)-(?P<code>\\d{4})\\) Dati da (?P<start_date>\\d{4}-\\d{2}-\\d{2}) a (?P<end_date>\\d{4}-\\d{2}-\\d{2})\"\n",
    ")\n",
    "\n",
    "\n",
    "def parse_station_infos(station_info):\n",
    "    p = re.match(infos_pattern, station_info).groupdict()\n",
    "    p[\"start_date\"] = datetime.strptime(p[\"start_date\"], r\"%Y-%m-%d\").date()\n",
    "    p[\"end_date\"] = datetime.strptime(p[\"end_date\"], r\"%Y-%m-%d\").date()\n",
    "    return p\n",
    "\n",
    "\n",
    "stations = list(map(parse_station_infos, station_infos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_fragment_path(station_number, year) -> Path:\n",
    "    return base / \"fragments\" / f\"{station_number}\" / f\"{year}.csv\"\n",
    "\n",
    "\n",
    "def raw_temperature_fragment_path(station_number, year, part) -> Path:\n",
    "    return base / \"fragments\" / f\"{station_number}\" / f\"{year}_{part}_raw.csv\"\n",
    "\n",
    "\n",
    "def location_path(station_number) -> Path:\n",
    "    return base / \"locations\" / f\"{station_number}.csv\"\n",
    "\n",
    "\n",
    "def download_station_temperatures(\n",
    "    station, sessid, sleep_seed=5, progbar=None, validated=True\n",
    "):\n",
    "    start_date = station[\"start_date\"]\n",
    "    end_date = station[\"end_date\"]\n",
    "    years = range(start_date.year, end_date.year + 4, 3)\n",
    "    starts = [date(year, 1, 1) for year in years[:-1]]\n",
    "    ends = [date(year, 1, 1) for year in years[1:]]\n",
    "    any_downloaded = False\n",
    "    if progbar is None:\n",
    "        progbar = tqdm(leave=False, position=1)\n",
    "    progbar.reset(total=len(years) - 1)\n",
    "    progbar.set_description_str(station[\"name\"])\n",
    "    for start_date, end_date in zip(starts, ends):\n",
    "        year = start_date.year\n",
    "        path = temperature_fragment_path(station[\"code\"], year)\n",
    "        if path.exists():\n",
    "            progbar.update()\n",
    "            continue\n",
    "        any_downloaded = True\n",
    "        data = request_data(\n",
    "            station[\"code\"], sessid, start_date, end_date, \"T\", validated\n",
    "        )\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        path.write_text(data)\n",
    "        sleep(uniform(sleep_seed, sleep_seed + 2))\n",
    "        progbar.update()\n",
    "    progbar.refresh()\n",
    "    return any_downloaded\n",
    "\n",
    "\n",
    "# def download_station_raw_temperatures(station, sessid, sleep_seed=5, progbar=None):\n",
    "#     years = range(station[\"start_date\"].year, station[\"end_date\"].year + 1)\n",
    "#     starts = [date(year, 1, 1) for year in years] + [date(year, 6, 1) for year in years]\n",
    "#     ends = [date(year, 6, 1) for year in years] + [\n",
    "#         date(year + 1, 1, 1) for year in years\n",
    "#     ]\n",
    "#     parts = [1] * len(years) + [2] * len(years)\n",
    "#     any_downloaded = False\n",
    "#     if progbar is None:\n",
    "#         progbar = tqdm(leave=False, position=1)\n",
    "#     progbar.reset(total=2 * len(years))\n",
    "#     progbar.set_description_str(station[\"name\"])\n",
    "#     for start_date, end_date, part in zip(starts, ends, parts):\n",
    "#         year = start_date.year\n",
    "#         path = raw_temperature_fragment_path(station[\"code\"], year, part)\n",
    "#         if path.exists():\n",
    "#             progbar.update()\n",
    "#             continue\n",
    "#         any_downloaded = True\n",
    "#         data = request_data(station[\"code\"], sessid, start_date, end_date, \"rawT\", True)\n",
    "#         path.parent.mkdir(parents=True, exist_ok=True)\n",
    "#         path.write_text(data)\n",
    "#         sleep(uniform(sleep_seed, sleep_seed + 2))\n",
    "#         progbar.update()\n",
    "#     progbar.refresh()\n",
    "#     return any_downloaded\n",
    "\n",
    "\n",
    "def download_stations_location(station):\n",
    "    path = location_path(station[\"code\"])\n",
    "    if path.exists():\n",
    "        return False\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    data = request_data(\n",
    "        station[\"code\"], station[\"start_date\"], station[\"end_date\"], \"X\"\n",
    "    )\n",
    "    path.write_text(data)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in tqdm(stations):\n",
    "    with tqdm(leave=True, position=1) as internal_progbar:\n",
    "        try:\n",
    "            dwn = download_station_temperatures(\n",
    "                station,\n",
    "                \"6uviu4d729b2atc929bgtjudk6\",\n",
    "                sleep_seed=1,\n",
    "                progbar=internal_progbar,\n",
    "                validated=False,\n",
    "            )\n",
    "            if dwn:\n",
    "                sleep(uniform(2, 5))\n",
    "        except Exception as e:\n",
    "            print(f\"There was an error downloading {station['name']}: {e}\")\n",
    "            sleep(uniform(60, 90))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in tqdm(stations):\n",
    "    try:\n",
    "        dwn = download_stations_location(station)\n",
    "        if dwn:\n",
    "            sleep(uniform(1, 2))\n",
    "    except Exception as e:\n",
    "        print(f\"There was an error downloading {station['name']}: {e}\")\n",
    "        sleep(uniform(4, 5))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars.selectors as cs\n",
    "\n",
    "metadata = (\n",
    "    pl.concat(\n",
    "        [\n",
    "            pl.read_csv(station_meta)\n",
    "            for station_meta in (base / \"locations\").glob(\"*.csv\")\n",
    "        ],\n",
    "        # axis=0,\n",
    "        # ignore_index=True,\n",
    "        how=\"vertical\",\n",
    "    )\n",
    "    .with_columns(cs.string().str.strip_chars())\n",
    "    .rename({\" Longitudine\": \"lon\", \" Latitudine\": \"lat\", \" Quota [m]\": \"elevation\", \"Codice sensore\": \"original_id\", \" Nome stazione\": \"name\"})\n",
    ")\n",
    "stats_pl = pl.from_records(\n",
    "    stations,\n",
    "    schema={\n",
    "        \"name\": pl.Utf8(),\n",
    "        \"kind\": pl.Utf8(),\n",
    "        \"code\": pl.Utf8(),\n",
    "        \"start_date\": pl.Date(),\n",
    "        \"end_date\": pl.Date(),\n",
    "    },\n",
    ").with_columns(pl.col(\"code\").cast(pl.Int64()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.join(stats_pl.select([\"code\", \"kind\"]), left_on=\"original_id\", right_on=\"code\", how=\"left\").write_csv(base / \"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fragment in (base / \"fragments\").glob(\"**/*.csv\"):\n",
    "    if fragment.stat().st_size < 360:\n",
    "        fragment.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0088030c36b4cb0b0578c0b8a09e39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_possibly_malformed_csv(path: Path, **kwargs) -> pl.DataFrame:\n",
    "    return (\n",
    "        pl.read_csv(path, truncate_ragged_lines=True, ignore_errors=False, **kwargs)\n",
    "        .with_columns(\n",
    "            pl.col(\"anno\").str.strip_chars().cast(pl.Int32),\n",
    "            pl.col(\"mese\").str.strip_chars().cast(pl.Int32),\n",
    "            pl.col(\"giorno\").str.strip_chars().cast(pl.Int32),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def read_agg_fragments(station_code):\n",
    "    data_folder = base / \"fragments\" / f\"{station_code}\"\n",
    "    available_tables = list(\n",
    "        filter(lambda path: not path.stem.endswith(\"_raw\"), data_folder.glob(\"*.csv\"))\n",
    "    )\n",
    "    if len(available_tables) == 0:\n",
    "        return None\n",
    "    all_tables = [\n",
    "        read_possibly_malformed_csv(\n",
    "            fragment,\n",
    "            columns=[0, 1, 2, 3, 11, 18, 24, 25, 26],\n",
    "            dtypes=[\n",
    "                pl.Int32(),\n",
    "                pl.Utf8(),\n",
    "                pl.Utf8(),\n",
    "                pl.Utf8(),\n",
    "                pl.Float64(),\n",
    "                pl.Float64(),\n",
    "                pl.Int32(),\n",
    "                pl.Float64(),\n",
    "                pl.Int32(),\n",
    "            ],\n",
    "            new_columns=[\n",
    "                \"codice_sensore\",\n",
    "                \"anno\",\n",
    "                \"mese\",\n",
    "                \"giorno\",\n",
    "                \"tmin\",\n",
    "                \"tmax\",\n",
    "                \"num_valori\",\n",
    "                \"quality\",\n",
    "                \"codice_stazione\",\n",
    "            ],\n",
    "            null_values=[\"  Dato mancante\", \"\"],\n",
    "        )\n",
    "        for fragment in available_tables\n",
    "    ]\n",
    "    return (\n",
    "        pl.concat(all_tables, how=\"vertical\")\n",
    "        .with_columns(date=pl.date(pl.col(\"anno\"), pl.col(\"mese\"), pl.col(\"giorno\")))\n",
    "        .drop([\"anno\", \"mese\", \"giorno\"])\n",
    "        .filter(pl.col(\"num_valori\").gt(0))\n",
    "    )\n",
    "\n",
    "\n",
    "for station in tqdm(stations):\n",
    "    try:\n",
    "        station_data = read_agg_fragments(station[\"code\"])\n",
    "        if station_data is not None:\n",
    "            station_data.write_parquet(base / \"dataset\" / f\"{station['code']}.parquet\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {station['code']}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(base / \"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codice sensore</th>\n",
       "      <th>Longitudine</th>\n",
       "      <th>Latitudine</th>\n",
       "      <th>Quota [m]</th>\n",
       "      <th>Codice stazione</th>\n",
       "      <th>Nome stazione</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2902</td>\n",
       "      <td>12°30'</td>\n",
       "      <td>43°48'</td>\n",
       "      <td>172.72</td>\n",
       "      <td>102</td>\n",
       "      <td>Bronzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2719</td>\n",
       "      <td>13°25'</td>\n",
       "      <td>43°17'</td>\n",
       "      <td>232.00</td>\n",
       "      <td>2100</td>\n",
       "      <td>Lornano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2725</td>\n",
       "      <td>13°35'</td>\n",
       "      <td>42°51'</td>\n",
       "      <td>136.00</td>\n",
       "      <td>2390</td>\n",
       "      <td>Ascoli Piceno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2731</td>\n",
       "      <td>13°23'</td>\n",
       "      <td>43°28'</td>\n",
       "      <td>83.80</td>\n",
       "      <td>7</td>\n",
       "      <td>Montepolesco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2692</td>\n",
       "      <td>13°30'</td>\n",
       "      <td>43°29'</td>\n",
       "      <td>123.00</td>\n",
       "      <td>162</td>\n",
       "      <td>Osimo Monteragolo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1625</td>\n",
       "      <td>13Ḟ35'</td>\n",
       "      <td>43Ḟ6'</td>\n",
       "      <td>200.00</td>\n",
       "      <td>147</td>\n",
       "      <td>Grottazzolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2884</td>\n",
       "      <td>13°24'</td>\n",
       "      <td>42°46'</td>\n",
       "      <td>393.00</td>\n",
       "      <td>620</td>\n",
       "      <td>Acquasanta Terme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2648</td>\n",
       "      <td>12°59'</td>\n",
       "      <td>42°59'</td>\n",
       "      <td>960.00</td>\n",
       "      <td>131</td>\n",
       "      <td>Monte Cavallo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2714</td>\n",
       "      <td>13°7'</td>\n",
       "      <td>43°23'</td>\n",
       "      <td>516.00</td>\n",
       "      <td>1860</td>\n",
       "      <td>Apiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>3152</td>\n",
       "      <td>13°9'</td>\n",
       "      <td>42°53'</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>191</td>\n",
       "      <td>Gualdo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Codice sensore  Longitudine  Latitudine   Quota [m]   Codice stazione  \\\n",
       "0              2902       12°30'      43°48'      172.72               102   \n",
       "1              2719       13°25'      43°17'      232.00              2100   \n",
       "2              2725       13°35'      42°51'      136.00              2390   \n",
       "3              2731       13°23'      43°28'       83.80                 7   \n",
       "4              2692       13°30'      43°29'      123.00               162   \n",
       "..              ...          ...         ...         ...               ...   \n",
       "152            1625       13Ḟ35'       43Ḟ6'      200.00               147   \n",
       "153            2884       13°24'      42°46'      393.00               620   \n",
       "154            2648       12°59'      42°59'      960.00               131   \n",
       "155            2714        13°7'      43°23'      516.00              1860   \n",
       "156            3152        13°9'      42°53'     1000.00               191   \n",
       "\n",
       "           Nome stazione  \n",
       "0                 Bronzo  \n",
       "1                Lornano  \n",
       "2          Ascoli Piceno  \n",
       "3           Montepolesco  \n",
       "4      Osimo Monteragolo  \n",
       "..                   ...  \n",
       "152        Grottazzolina  \n",
       "153     Acquasanta Terme  \n",
       "154        Monte Cavallo  \n",
       "155                Apiro  \n",
       "156               Gualdo  \n",
       "\n",
       "[157 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
