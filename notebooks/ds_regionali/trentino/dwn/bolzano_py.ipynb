{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path.home() / \"Local_Workspace\" / \"Datasets\" / \"ARPA\" / \"TRENTINO\" / \"bolzano\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Bolzano\n",
    "Stazioni recuperabili tramite API OpenData. Solo dal 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = pl.read_json(base / \"api\" / \"sensors.json\").with_columns(\n",
    "    pl.col(\"SCODE\").str.to_uppercase().str.strip_chars()\n",
    ")\n",
    "sensors.write_csv(base / \"api\" / \"sensors.csv\")\n",
    "stations = gpd.read_file(base / \"api\" / \"stations.geojson\")\n",
    "stations[\"SCODE\"] = stations[\"SCODE\"].str.upper().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_payload(station_code, from_date: datetime, to_date: datetime):\n",
    "    return {\n",
    "        \"station_code\": station_code,\n",
    "        \"sensor_code\": \"LT\",\n",
    "        \"date_from\": from_date.strftime(r\"%Y%m%d\"),\n",
    "        \"date_to\": to_date.strftime(r\"%Y%m%d\"),\n",
    "        \"output_format\": \"CSV\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_ids = sensors.filter(pl.col(\"TYPE\").eq(\"LT\"))[\"SCODE\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "def file_path(station_id, year):\n",
    "    path = base / \"api\" / \"fragments\" / f\"{station_id}\" / f\"{year}.csv\"\n",
    "    if not path.parent.exists():\n",
    "        path.parent.mkdir(parents=True)\n",
    "    return path\n",
    "\n",
    "\n",
    "def get_year_data(station_id, year):\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            \"http://daten.buergernetz.bz.it/services/meteo/v1/timeseries\",\n",
    "            params=query_payload(\n",
    "                station_id, datetime(year, 1, 1), datetime(year + 1, 1, 1)\n",
    "            ),\n",
    "        )\n",
    "        if r.status_code != 200:\n",
    "            sleep(uniform(0.2, 1))\n",
    "            raise\n",
    "        return r.text\n",
    "    except:\n",
    "        print(f\"There was an error: {r.status_code}. Continuing...\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_station_data(station_id, bar: tqdm):\n",
    "    for year in range(2010, 2025):\n",
    "        path = file_path(station_id, year)\n",
    "        if path.exists():\n",
    "            bar.update()\n",
    "            continue\n",
    "        data = get_year_data(station_id, year)\n",
    "        if not data:\n",
    "            bar.update()\n",
    "            continue\n",
    "        if data.strip() == \"\":\n",
    "            bar.update()\n",
    "            continue\n",
    "        with open(path, \"wt\") as file:\n",
    "            file.write(data)\n",
    "        bar.update()\n",
    "        sleep(uniform(0.5, 1.5))\n",
    "    bar.reset(total=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in tqdm(stat_ids):\n",
    "    with tqdm(total=15, leave=True) as bar:\n",
    "        get_station_data(station_id, bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list((base / \"api\" / \"fragments\").glob(\"**/*.csv\"))[:1]:\n",
    "    data = pl.read_csv(file, try_parse_dates=False).with_columns(\n",
    "        pl.col(\"DATE\")\n",
    "        .str.replace(\"CET\", \"+0100\")\n",
    "        .str.replace(\"CEST\", \"+0200\")\n",
    "        .str.to_datetime(format=r\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        .dt.convert_time_zone(time_zone=\"CET\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in (base / \"api\" / \"fragments\").glob(\"**/*.csv\"):\n",
    "    station_id = file.parent.stem\n",
    "    file_path = base / \"api\" / \"dataset\" / f\"{station_id}\" / f\"{file.stem}.parquet\"\n",
    "    if not file_path.parent.exists():\n",
    "        file_path.parent.mkdir(parents=True)\n",
    "    pl.read_csv(file, try_parse_dates=False).with_columns(\n",
    "        pl.col(\"DATE\")\n",
    "        .str.replace(\"CET\", \"+0100\")\n",
    "        .str.replace(\"CEST\", \"+0200\")\n",
    "        .str.to_datetime(format=r\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        .dt.convert_time_zone(time_zone=\"CET\"),\n",
    "        pl.lit(station_id).str.to_uppercase().str.strip_chars().alias(\"original_id\"),\n",
    "    ).write_parquet(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLSX Data\n",
    "Sempre da OpenData ma in formato tabelle excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = (base / \"xlsx\" / \"xlsx_datastore.html\").read_text()\n",
    "landing_page = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def li_class_resource_item(li):\n",
    "    return li.has_attr(\"class\") and \"resource-item\" in li[\"class\"]\n",
    "\n",
    "\n",
    "ids = [tag[\"data-id\"] for tag in landing_page.find_all(li_class_resource_item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "files = list(map(lambda m: m.group(0), re.finditer(r\"http://[^\\\"]+\\.xlsx\", page)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "with requests.Session() as session:\n",
    "    for url in tqdm(files):\n",
    "        r = session.get(url)\n",
    "        with open(\n",
    "            base / \"xlsx\" / urllib.parse.unquote(url.split(\"/\")[-1]), \"wb\"\n",
    "        ) as file:\n",
    "            file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payload(data_id, n, offset):\n",
    "    return {\n",
    "        \"resource_id\": data_id,\n",
    "        \"limit\": n,\n",
    "        \"offset\": offset,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_data(data_id, n, offset):\n",
    "    return requests.get(\n",
    "        \"https://data.civis.bz.it/api/action/datastore_search\",\n",
    "        params=payload(data_id, n, offset),\n",
    "    ).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "excels_path = base / \"xlsx\"\n",
    "xlsx_files = list(excels_path.glob(\"*.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(path):\n",
    "    # ETRS89/UTM32N\n",
    "    coords = pd.read_excel(path, usecols=[7], skiprows=7, nrows=3, header=None)\n",
    "    meta = coords.iloc[:, 0].str.split(\" \").explode().iloc[[1, 3, 4]]\n",
    "    meta.index = [\"x\", \"y\", \"elevation\"]\n",
    "    return meta\n",
    "\n",
    "# def alt_get_meta(path):\n",
    "#     import openpyxl\n",
    "#     ws = openpyxl.load_workbook(path, read_only=True)[\"Min-Max Extremwert-estremo\"]\n",
    "#     x = ws[\"J10\"].value\n",
    "#     y = ws[\"P10\"].value\n",
    "#     elevation = ws[\"BA10\"].value\n",
    "#     meta = pd.Series({\"x\": x, \"y\": y, \"elevation\": elevation}).str.split(\" \").explode().iloc[[0, 2, 4]]\n",
    "#     return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "reg = re.compile(r\"-+\")\n",
    "meta_pattern = re.compile(r\"^(?P<original_id>[A-Z0-9]+)-+(?P<station_name_de>[^-]+)-+(?P<station_name_it>.+)-multiannual-LT-N-daily-temperature-precipitation\")\n",
    "def read_bz_excel(path):\n",
    "    # fname = path.stem.replace(re.compile(r\"-+\"), \"-\")\n",
    "    path_meta = meta_pattern.match(path.stem).groupdict()\n",
    "    # original_id, station_name = fname.split(\"-\", maxsplit=1)\n",
    "    # station_name = station_name.replace(\"-\", \" \")\n",
    "    # original_id = original_id.upper().strip()\n",
    "    station_name = path_meta[\"station_name_it\"].strip()\n",
    "    original_id = path_meta[\"original_id\"].upper().strip()\n",
    "\n",
    "    meta = get_meta(path)\n",
    "    meta[\"original_id\"] = original_id\n",
    "    meta[\"station_name\"] = station_name\n",
    "\n",
    "    data = pd.read_excel(\n",
    "        path,\n",
    "        skiprows=13,\n",
    "        usecols=[2, 4, 5],\n",
    "        names=[\"date\", \"T_MIN\", \"T_MAX\"],\n",
    "        na_values=\"---\",\n",
    "        dtype={\"T_MIN\": \"float\", \"T_MAX\": \"float\"},\n",
    "        skipfooter=1,\n",
    "    )\n",
    "    data = pl.from_pandas(data).with_columns(\n",
    "        pl.col(\"date\").str.to_date(format=r\"%d.%m.%Y\"),\n",
    "        pl.lit(original_id).alias(\"original_id\").str.to_uppercase().str.strip_chars(),\n",
    "        pl.lit(station_name).alias(\"station_name\"),\n",
    "    )\n",
    "    return data, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in xlsx_files:\n",
    "    try:\n",
    "        read_bz_excel(path)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not open {path} because {e}\")\n",
    "        # path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_things = [read_bz_excel(path) for path in excels_path.glob(\"*.xlsx\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = zip(*all_things)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.concat(data, how=\"vertical\")\n",
    "meta = pl.concat(\n",
    "    [pl.from_pandas(pd.DataFrame(m).transpose()) for m in meta], how=\"vertical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.with_columns(\n",
    "    pl.col(\"x\").str.to_integer(),\n",
    "    pl.col(\"y\").str.to_integer(),\n",
    "    pl.col(\"elevation\").str.to_integer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.write_csv(base / \"xlsx\" / \"meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.write_parquet(base / \"xlsx\" / \"data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
