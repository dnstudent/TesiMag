{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'C/UTF-8/C/C/C/C'"
      ],
      "text/latex": [
       "'C/UTF-8/C/C/C/C'"
      ],
      "text/markdown": [
       "'C/UTF-8/C/C/C/C'"
      ],
      "text/plain": [
       "[1] \"C/UTF-8/C/C/C/C\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setwd(fs::path_abs(\"~/Local_Workspace/TesiMag\"))\n",
    "Sys.setlocale(\"LC_ALL\", \"UTF-8\")\n",
    "library(dplyr, warn.conflicts = FALSE)\n",
    "library(openxlsx, warn.conflicts = FALSE)\n",
    "library(stringr, warn.conflicts = FALSE)\n",
    "library(stringi, warn.conflicts = FALSE)\n",
    "library(assertr, warn.conflicts = FALSE)\n",
    "\n",
    "source(\"src/database/startup.R\")\n",
    "source(\"src/database/query/data.R\")\n",
    "\n",
    "conns <- load_dbs()\n",
    "sets <- c(\"ER\", \"FVG\", \"LOM\", \"MAR\", \"TAA2\", \"TOS\", \"UMB\", \"VDA\", \"PIE\", \"LIG\", \"VEN\")\n",
    "datasets <- c(\"ARPAPiemonte\", \"ARPAV\", \"ARPAL\", \"ARPALombardia\", \"ARPAUmbria\", \"TAA\", \"SIRToscana\", \"Dext3r\", \"ARPAFVG\", \"ARPAM\", \"ISAC\", \"SCIA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rg <- \"LOM\"\n",
    "meta <- query_checkpoint_meta(rg, \"merged\", conns$data) |> collect()\n",
    "corrections <- read.xlsx(fs::path(\"external\", \"correzioni\", paste0(rg, \"_edit.xlsx\")))\n",
    "# mutate(name = stri_unescape_unicode(str_replace_all(name, regex(\"<U\\\\+(.{4})>\"), paste0(\"\\\\\\\\u\", \"\\\\1\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "corrections |>\n",
    "    mutate(across(c(from_sensor_keys, from_datasets), ~ str_split(., fixed(\"*\"), simplify = FALSE))) |>\n",
    "    select(name, from_sensor_keys, from_datasets) |>\n",
    "    inner_join(meta, by = c(\"from_sensor_keys\", \"from_datasets\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 0 x 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>name.now</th><th scope=col>name.manual</th><th scope=col>from_sensor_keys.now</th><th scope=col>from_sensor_keys.manual</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 0 x 4\n",
       "\\begin{tabular}{llll}\n",
       " name.now & name.manual & from\\_sensor\\_keys.now & from\\_sensor\\_keys.manual\\\\\n",
       " <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 0 x 4\n",
       "\n",
       "| name.now &lt;chr&gt; | name.manual &lt;chr&gt; | from_sensor_keys.now &lt;chr&gt; | from_sensor_keys.manual &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "\n"
      ],
      "text/plain": [
       "     name.now name.manual from_sensor_keys.now from_sensor_keys.manual"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta |>\n",
    "    rowwise() |>\n",
    "    mutate(across(starts_with(\"from_\"), ~ paste0(., collapse = \";\"))) |>\n",
    "    ungroup() |>\n",
    "    full_join(corrections, by = \"sensor_key\", suffix = c(\".now\", \".manual\")) |>\n",
    "    filter(name.now != name.manual | from_datasets.now != from_datasets.manual | from_sensor_keys.now != from_sensor_keys.manual | is.na(from_sensor_keys.now) | is.na(from_sensor_keys.manual)) |>\n",
    "    select(name.now, name.manual, from_sensor_keys.now, from_sensor_keys.manual) |>\n",
    "    as.data.frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "corrections <- fs::path_abs(\"./external/correzioni\") |>\n",
    "    fs::dir_ls(regex = regex(\"[^\\\\~]+_edit.xlsx\")) |>\n",
    "    purrr::map(\n",
    "        .f = \\(path) read.xlsx(path) |> select(sensor_key, dataset, from_sensor_keys, from_datasets, ends_with(\"_ok\"), ends_with(\"_precision\"), keep)\n",
    "    ) |>\n",
    "    bind_rows() |>\n",
    "    mutate(\n",
    "        sensor_key = as.integer(sensor_key),\n",
    "        from_datasets = str_split(from_datasets, regex(\";|\\\\*\")),\n",
    "        from_sensor_keys = str_split(from_sensor_keys, regex(\";|\\\\*\")) |> purrr::map(as.integer),\n",
    "        keep = coalesce(keep, TRUE),\n",
    "        loc_correction = !is.na(lon_ok) | !is.na(lat_ok),\n",
    "        elev_correction = !is.na(ele_ok),\n",
    "        loc_precision = if_else(loc_correction, coalesce(loc_precision, -1), coalesce(loc_precision, 0)) |> as.integer(),\n",
    "    ) |>\n",
    "    mutate(\n",
    "        elev_precision = if_else(elev_correction | (loc_precision == -1L), coalesce(elev_precision, -1), coalesce(elev_precision, 0)) |> as.integer()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "corrected_meta <- query_checkpoint_meta(sets, \"merged\", conns$data) |>\n",
    "    collect() |>\n",
    "    as.data.frame() |>\n",
    "    full_join(corrections, by = c(\"sensor_key\", \"dataset\", \"from_sensor_keys\", \"from_datasets\")) |>\n",
    "    assert(not_na, c(network, sensor_key, dataset, from_sensor_keys, from_datasets)) |>\n",
    "    mutate(\n",
    "        lon = coalesce(lon_ok, lon),\n",
    "        lat = coalesce(lat_ok, lat),\n",
    "        elevation = coalesce(ele_ok, elevation),\n",
    "        name = coalesce(name_ok, name)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "metadata <- query_checkpoint_meta(datasets, \"raw\", conns$data) |> collect()\n",
    "\n",
    "groups_table <- query_parquet(fs::path_wd(\"db\", \"extra\", \"series_groups\", sets, ext = \"parquet\"), filename = T) |>\n",
    "    mutate(set = parse_filename(filename, TRUE)) |>\n",
    "    select(-filename) |>\n",
    "    collect()\n",
    "\n",
    "network_rank_table <- tribble(\n",
    "    ~dataset, ~network, ~network_rank,\n",
    "    \"ISAC\", \"ISAC\", 1L, # ISAC series are always ranked first\n",
    "    \"ISAC\", \"DPC\", 4L #  DPC series are always ranked last\n",
    ") |>\n",
    "    bind_rows(\n",
    "        metadata |> filter(dataset == \"SCIA\") |> distinct(dataset, network) |> mutate(network_rank = 3L) #  SCIA series are ranked second to last\n",
    "    ) |>\n",
    "    bind_rows(\n",
    "        metadata |> filter(!dataset %in% c(\"SCIA\", \"ISAC\")) |> distinct(dataset, network) |> mutate(network_rank = 2L) # ARPA series are ranked second\n",
    "    )\n",
    "\n",
    "# VEDERE SE USARE: ASSEGNAZIONE RANKING PER LUNGHEZZA DELLA SERIE, IN MODO DA NON PRENDERE COME RIFERIMENTO UNA SERIE TROPPO CORTE\n",
    "length_rank_table <- tribble(\n",
    "    ~from, ~to, ~length_rank,\n",
    "    0L, 365L * 4L, 2L,\n",
    "    365L * 4L + 1L, Inf, 1L\n",
    ") # ???\n",
    "\n",
    "gs <- groups_table |>\n",
    "    left_join(metadata |> select(dataset, sensor_key, network, sensor_last), by = c(\"dataset\", \"sensor_key\"))\n",
    "\n",
    "ranked_groups <- gs |>\n",
    "    left_join(network_rank_table, by = c(\"dataset\", \"network\")) |>\n",
    "    group_by(set, gkey, variable) |>\n",
    "    arrange(network_rank, desc(sensor_last), .by_group = TRUE) |>\n",
    "    mutate(rank = row_number(), skip_correction = \"ISAC\" %in% network) |>\n",
    "    ungroup() |>\n",
    "    select(!c(sensor_last, network_rank, network, from))\n",
    "\n",
    "# ignore_corrections <- make_exclusion_table(tagged_analysis, NULL, network_x == \"ISAC\" | network_y == \"ISAC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"notebooks/merging/correzioni_manuali.R\")\n",
    "ds_path <- fs::path_wd(\"data\")\n",
    "rk_test <- ranked_groups |> slice_head(n = 2L)\n",
    "offs <- dynamic_merge.group(ds_path, rk_test, 10, 0L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"notebooks/merging/correzioni_manuali.R\")\n",
    "dynamic_merge.full(ds_path, fs::path_wd(\"merged_db\"), ranked_groups, 10, 0L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "merged_data <- open_dataset(fs::path(fs::path_wd(\"merged_db\"), \"data\"))\n",
    "merged_meta <- open_dataset(fs::path(fs::path_wd(\"merged_db\"), \"meta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemDataset with 6038 Parquet files\n",
       "date: date32[day]\n",
       "from_dataset: string\n",
       "from_sensor_key: int32\n",
       "value: double\n",
       "set: string\n",
       "gkey: int32\n",
       "variable: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemDataset with 6038 Parquet files\n",
       "gkey: int32\n",
       "variable: int32\n",
       "sensor_key: int32\n",
       "dataset: string\n",
       "set: string\n",
       "rank: int32\n",
       "skip_correction: bool\n",
       "k0: double\n",
       "k1: double\n",
       "k2: double\n",
       "k3: double\n",
       "merged: bool\n",
       "offset: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
