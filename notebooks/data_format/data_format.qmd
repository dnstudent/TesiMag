---
title: "Converting the merged dataset format"
author: "Davide Nicoli"
format: html
---

## Init

```{r}
Sys.setlocale("LC_ALL", "UTF-8")
library(dplyr, warn.conflicts = FALSE)
library(arrow, warn.conflicts = FALSE)
library(zeallot, warn.conflicts = FALSE)
library(openxlsx, warn.conflicts = FALSE)
library(tidyr, warn.conflicts = FALSE)

source("src/database/startup.R")
source("src/database/query/data.R")
source("src/merging/combining.R")
source("notebooks/corrections/manual_corrections.R")

ds4conv_dir <- fs::path("db", "tmp", "dataset4conv")
conns <- load_dbs()
datasets <- c("ARPAPiemonte", "ARPAL", "ARPALombardia", "ARPAV", "TAA", "ARPAFVG", "Dext3r", "SIRToscana", "ARPAUmbria", "ARPAM", "SCIA", "ISAC", "MeteoFrance", "GeoSphereAustria", "ARSO", "MeteoSwissNBCN", "SwissMetNet")
sets <- c("PIE", "LIG", "LOM", "VEN", "TAA2", "FVG", "ER", "TOS", "UMB", "MAR", "VDA", "FRA", "AUT", "SLO", "SWI")
save_to <- fs::path("db", "conv", "merged_corrected")
```

Preparazione delle tabelle di dati d'origine in un formato utilizzabile velocemente

```{r}
if (fs::dir_exists(ds4conv_dir)) unlink(ds4conv_dir, recursive = TRUE)

ds_files <- fs::path(archive_path("full", "data", "merged_corrected"), "**", "*.parquet")
DBI::dbExecute(
  conns$data,
  stringr::str_glue(
    "
    CREATE OR REPLACE VIEW ds_4conv_tmp AS
    SELECT *
    FROM read_parquet('{ds_files}', hive_partitioning = true, hive_types = {{'variable': INT}})
    "
  )
)
DBI::dbExecute(
  conns$data,
  stringr::str_glue(
    "
    COPY ds_4conv_tmp
    TO '{ds4conv_dir}' (FORMAT PARQUET, PARTITION_BY (dataset, series_key, variable), FILENAME_PATTERN 'part-{{i}}')
    "
  )
)

print("âœ…")
```

Scrittura delle tabelle csv "convertite"

```{r}
base <- fs::path_abs(".")
integrators_root <- fs::path(base, "db", "tmp", "prepared4merge")
variable_names <- tibble(variable = c(-1L, 1L), variable_name = c("TMND", "TMXD"))
merge_specs <- open_dataset(fs::path("db", "extra", "merge_specs"))

unlink(fs::path(save_to, "data"), recursive = TRUE)
merge_specs |>
  collect() |>
  left_join(variable_names, by = "variable", relationship = "many-to-one") |>
  group_split(dataset, series_key, variable) |>
  purrr::walk(~ {
    dataset <- .x$dataset |> first()
    series_key <- .x$series_key |> first()
    variable <- .x$variable |> first()
    variable_name <- .x$variable_name |> first()
    master_path <- fs::path(ds4conv_dir, str_glue("dataset={dataset}"), str_glue("series_key={series_key}"), str_glue("variable={variable}"), "part-0.parquet")
    master_series <- read_parquet(master_path)
    c(integrators, cols) %<-% load_data.group.1(integrators_root, .x)
    save_to_path <- fs::path(save_to, "data", str_glue("{variable_name}_{dataset}_{stringr::str_pad(series_key, 3L, side = 'left', pad = '0')}.csv"))
    if (!fs::dir_exists(fs::path_dir(save_to_path))) fs::dir_create(fs::path_dir(save_to_path), recurse = TRUE)
    full_join(master_series |> rename(master = value, master_raw = value_raw), integrators, by = "date") |>
      arrange(date) |>
      select(date, master, master_raw, all_of(cols), from_dataset, from_sensor_key) |>
      unite("from", from_dataset, from_sensor_key, sep = "/") |>
      complete(date = seq.Date(min(date), max(date), by = "day")) |>
      arrange(date) |>
      write_csv_arrow(save_to_path, write_options = csv_write_options(quoting_style = "AllValid"))
  }, .progress = TRUE)


print("Converted merged dataset to csv")
```

Scrittura delle tabelle di metadati e specifiche del merging

```{r}
prepare_lists_and_from <- function(metas) {
  metas |>
    rowwise() |>
    mutate(from = list(str_c(from_datasets, from_sensor_keys, sep = "/")), across(where(is.list), ~ paste0(., collapse = ";"))) |>
    ungroup() |>
    select(-from_datasets, -from_sensor_keys)
}

if (!fs::dir_exists(fs::path(save_to, "metadata"))) {
  fs::dir_create(fs::path(save_to, "metadata"), recurse = TRUE)
}

mrc <- query_checkpoint_meta("full", "merged_corrected", conns$data) |>
  collect() |>
  assertr::assert(not_na, dataset, series_key, from_datasets, from_sensor_keys) |>
  prepare_lists_and_from() |>
  relocate(dataset, series_key, from, name)
mrc |> vroom::vroom_write(fs::path(save_to, "metadata", "metadata.csv"))
mrc |> openxlsx::write.xlsx(fs::path(save_to, "metadata", "metadata.xlsx"), asTable = TRUE)

ms <- open_dataset(fs::path("db", "extra", "merge_specs")) |>
  collect() |>
  assertr::assert(not_na, everything()) |>
  unite("from", from_dataset, from_sensor_key, sep = "/")
ms |> vroom::vroom_write(fs::path(save_to, "metadata", "merge_specs.csv"))
ms |> openxlsx::write.xlsx(fs::path(save_to, "metadata", "merge_specs.xlsx"), asTable = TRUE)
```

```{r}
merged_metadata <- query_checkpoint_meta(sets, "merged", conns$data) |>
  collect()

corrections <- load_corrections(fs::path("external", "correzioni"))

corrections1 <- merged_metadata |>
  select(dataset, series_key, from_datasets, from_sensor_keys, name, lon, lat, elevation) |>
  rowwise() |>
  mutate(across(where(is.list), ~ paste0(., collapse = ";"))) |>
  ungroup() |>
  left_join(corrections, by = c("dataset", "from_datasets", "from_sensor_keys"), relationship = "one-to-one") |>
  prepare_corrections(merged_metadata)

corrections_path <- fs::path(save_to, "metadata", "manual_corrections.xlsx")
if (!fs::dir_exists(fs::path_dir(corrections_path))) fs::dir_create(fs::path_dir(corrections_path), recurse = TRUE)
ccs <- corrections1 |>
  prepare_lists_and_from() |>
  rename(original_lon = lon, original_lat = lat, original_elevation = elevation, manual_lon = lon_ok, manual_lat = lat_ok, manual_elevation = ele_ok, manual_name = name_ok, manual_user_code = user_code_ok)
ccs |> vroom::vroom_write(fs::path(save_to, "metadata", "manual_corrections.csv"))
ccs |> openxlsx::write.xlsx(fs::path(save_to, "metadata", "manual_corrections.xlsx"), asTable = TRUE)
```

Tabella con i metadati originali

```{r}
original_metadata <- query_checkpoint_meta(datasets, "raw", conns$data) |>
  collect()
original_metadata |> vroom::vroom_write(fs::path(save_to, "metadata", "starting_metadata.csv"))
original_metadata |> openxlsx::write.xlsx(fs::path(save_to, "metadata", "starting_metadata.xlsx"))
```
