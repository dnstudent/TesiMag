{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from time import sleep\n",
    "from random import uniform\n",
    "from io import StringIO\n",
    "from datetime import datetime, date\n",
    "\n",
    "base = Path.home() / \"Local_Workspace\" / \"Datasets\" / \"ARPA\" / \"MARCHE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {\"T\": \"TminMdmx\", \"X\": \"LonLat_Z\", \"rawT\": \"Temp_Val\"}\n",
    "\n",
    "\n",
    "def arpam_payload(\n",
    "    station_codes, from_date: datetime, to_date: datetime, variable, validated=True\n",
    "):\n",
    "    if type(station_codes) == str:\n",
    "        station_codes = [station_codes]\n",
    "    payload = {\n",
    "        \"sessid\": \"9oqbigf87uqb9fdco9bii0fkmd\",\n",
    "        \"outputType\": \"file\",\n",
    "        \"SelezionaStazione[]\": [f\"{code}\" for code in station_codes],\n",
    "        \"TipoDato\": \"validato\" if validated else \"originale\",\n",
    "        \"TipoTabella\": f\"{variables[variable]}\",\n",
    "        \"BeginDate\": from_date.strftime(r\"%Y-%m-%d+00:00\"),\n",
    "        \"EndDate\": to_date.strftime(r\"%Y-%m-%d+00:00\"),\n",
    "        \"LineNumberPdf\": \"0\",\n",
    "    }\n",
    "    if variable == \"T\":\n",
    "        payload[\"TimeStepType\"] = \"d\"\n",
    "        payload[\"TimeStep\"] = \"1\"\n",
    "    return payload\n",
    "\n",
    "\n",
    "def arpam_cookies(sessid=\"9oqbigf87uqb9fdco9bii0fkmd\"):\n",
    "    return {\n",
    "        \"displayCookieConsent\": \"y\",\n",
    "        \"PHPSESSID\": sessid,\n",
    "    }\n",
    "\n",
    "\n",
    "def arpam_headers():\n",
    "    return {\n",
    "        \"Host\": \"app.protezionecivile.marche.it\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"it-IT,it;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "        \"Content-Length\": \"215\",\n",
    "        \"Origin\": \"http://app.protezionecivile.marche.it\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Referer\": \"http://app.protezionecivile.marche.it/sol/temperatura/menu.sol?lang=it\",\n",
    "        # \"Cookie\": f\"displayCookieConsent=y; displayCookieConsent=y; PHPSESSID={sessid}\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Pragma\": \"no-cache\",\n",
    "        \"Cache-Control\": \"no-cache\",\n",
    "    }\n",
    "\n",
    "\n",
    "def request_data(stat_number, from_date, to_date, variable, validated=True):\n",
    "    r = requests.post(\n",
    "        \"http://app.protezionecivile.marche.it/sol/temperatura/queryResultsFile.sol?lang=it\",\n",
    "        data=arpam_payload(stat_number, from_date, to_date, variable, validated),\n",
    "        headers=arpam_headers(),\n",
    "        cookies=arpam_cookies(),\n",
    "    )\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_page = BeautifulSoup((base / \"form.html\").read_text(), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_options(tag):\n",
    "    return tag.has_attr(\"data-multiselectid\") and tag[\"data-multiselectid\"].startswith(\n",
    "        \"multiselect_7qo2j7oogv7\"\n",
    "    )\n",
    "\n",
    "\n",
    "opts = form_page.find_all(station_options)\n",
    "station_numbers = [opt[\"value\"] for opt in opts]\n",
    "station_infos = [opt.text for opt in opts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "infos_pattern = re.compile(\n",
    "    r\"(?P<name>[^\\(]+) \\((?P<kind>R.)-(?P<code>\\d{4})\\) Dati da (?P<start_date>\\d{4}-\\d{2}-\\d{2}) a (?P<end_date>\\d{4}-\\d{2}-\\d{2})\"\n",
    ")\n",
    "\n",
    "\n",
    "def parse_station_infos(station_info):\n",
    "    p = re.match(infos_pattern, station_info).groupdict()\n",
    "    p[\"start_date\"] = datetime.strptime(p[\"start_date\"], r\"%Y-%m-%d\").date()\n",
    "    p[\"end_date\"] = datetime.strptime(p[\"end_date\"], r\"%Y-%m-%d\").date()\n",
    "    return p\n",
    "\n",
    "\n",
    "stations = list(map(parse_station_infos, station_infos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_fragment_path(station_number, year) -> Path:\n",
    "    return base / \"fragments\" / f\"{station_number}\" / f\"{year}.csv\"\n",
    "\n",
    "\n",
    "def raw_temperature_fragment_path(station_number, year, part) -> Path:\n",
    "    return base / \"fragments\" / f\"{station_number}\" / f\"{year}_{part}_raw.csv\"\n",
    "\n",
    "\n",
    "def location_path(station_number) -> Path:\n",
    "    return base / \"locations\" / f\"{station_number}.csv\"\n",
    "\n",
    "\n",
    "def download_station_temperatures(station, sleep_seed=5, progbar=None):\n",
    "    start_date = max(date(2000, 1, 1), station[\"start_date\"])\n",
    "    end_date = max(date(2000, 1, 2), station[\"end_date\"])\n",
    "    years = range(start_date.year, end_date.year + 1)\n",
    "    starts = [date(year, 1, 1) for year in years]\n",
    "    ends = [date(year + 1, 1, 1) for year in years]\n",
    "    any_downloaded = False\n",
    "    if progbar is None:\n",
    "        progbar = tqdm(leave=False, position=1)\n",
    "    progbar.reset(total=len(years))\n",
    "    progbar.set_description_str(station[\"name\"])\n",
    "    for start_date, end_date in zip(starts, ends):\n",
    "        year = start_date.year\n",
    "        path = temperature_fragment_path(station[\"code\"], year)\n",
    "        if path.exists():\n",
    "            progbar.update()\n",
    "            continue\n",
    "        any_downloaded = True\n",
    "        data = request_data(station[\"code\"], start_date, end_date, \"T\", True)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        path.write_text(data)\n",
    "        sleep(uniform(sleep_seed, sleep_seed + 2))\n",
    "        progbar.update()\n",
    "    progbar.refresh()\n",
    "    return any_downloaded\n",
    "\n",
    "\n",
    "def download_station_raw_temperatures(station, sleep_seed=5, progbar=None):\n",
    "    years = range(station[\"start_date\"].year, station[\"end_date\"].year + 1)\n",
    "    starts = [date(year, 1, 1) for year in years] + [date(year, 6, 1) for year in years]\n",
    "    ends = [date(year, 6, 1) for year in years] + [\n",
    "        date(year + 1, 1, 1) for year in years\n",
    "    ]\n",
    "    parts = [1] * len(years) + [2] * len(years)\n",
    "    any_downloaded = False\n",
    "    if progbar is None:\n",
    "        progbar = tqdm(leave=False, position=1)\n",
    "    progbar.reset(total=2 * len(years))\n",
    "    progbar.set_description_str(station[\"name\"])\n",
    "    for start_date, end_date, part in zip(starts, ends, parts):\n",
    "        year = start_date.year\n",
    "        path = raw_temperature_fragment_path(station[\"code\"], year, part)\n",
    "        if path.exists():\n",
    "            progbar.update()\n",
    "            continue\n",
    "        any_downloaded = True\n",
    "        data = request_data(station[\"code\"], start_date, end_date, \"rawT\", True)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        path.write_text(data)\n",
    "        sleep(uniform(sleep_seed, sleep_seed + 2))\n",
    "        progbar.update()\n",
    "    progbar.refresh()\n",
    "    return any_downloaded\n",
    "\n",
    "\n",
    "def download_stations_location(station):\n",
    "    path = location_path(station[\"code\"])\n",
    "    if path.exists():\n",
    "        return False\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    data = request_data(\n",
    "        station[\"code\"], station[\"start_date\"], station[\"end_date\"], \"X\"\n",
    "    )\n",
    "    path.write_text(data)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63f21157b294fa6b0923301a32228ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_station_raw_temperatures(stations[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in tqdm(stations):\n",
    "    with tqdm(leave=True, position=1) as internal_progbar:\n",
    "        try:\n",
    "            dwn = download_station_temperatures(\n",
    "                station, sleep_seed=2, progbar=internal_progbar\n",
    "            )\n",
    "            if dwn:\n",
    "                sleep(uniform(10, 15))\n",
    "        except Exception as e:\n",
    "            print(f\"There was an error downloading {station['name']}: {e}\")\n",
    "            sleep(uniform(60, 90))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in tqdm(stations):\n",
    "    try:\n",
    "        dwn = download_stations_location(station)\n",
    "        if dwn:\n",
    "            sleep(uniform(1, 2))\n",
    "    except Exception as e:\n",
    "        print(f\"There was an error downloading {station['name']}: {e}\")\n",
    "        sleep(uniform(4, 5))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [pd.read_csv(station_meta) for station_meta in (base / \"locations\").glob(\"*.csv\")],\n",
    "    axis=0,\n",
    "    ignore_index=True,\n",
    ").to_csv(base / \"metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fragment in (base / \"fragments\").glob(\"**/*.csv\"):\n",
    "    if fragment.stat().st_size < 360:\n",
    "        fragment.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_list = [base / \"fragments\" / f\"{station['code']}\" for station in stations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Montegranaro',\n",
       " 'kind': 'RT',\n",
       " 'code': '3471',\n",
       " 'start_date': datetime.date(2023, 2, 2),\n",
       " 'end_date': datetime.date(2023, 12, 27)}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd2a68996974267af3848cec9b8b500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_possibly_malformed_csv(path: Path, **kwargs) -> pl.DataFrame:\n",
    "    return (\n",
    "        pl.read_csv(path, truncate_ragged_lines=True, ignore_errors=False, **kwargs)\n",
    "        .with_columns(\n",
    "            pl.col(\"anno\").str.strip_chars().cast(pl.Int32),\n",
    "            pl.col(\"mese\").str.strip_chars().cast(pl.Int32),\n",
    "            pl.col(\"giorno\").str.strip_chars().cast(pl.Int32),\n",
    "        )\n",
    "        .filter(pl.col(\"anno\").eq(int(path.stem)))\n",
    "    )\n",
    "\n",
    "\n",
    "def read_agg_fragments(station_code):\n",
    "    data_folder = base / \"fragments\" / f\"{station_code}\"\n",
    "    available_tables = list(\n",
    "        filter(lambda path: not path.stem.endswith(\"_raw\"), data_folder.glob(\"*.csv\"))\n",
    "    )\n",
    "    if len(available_tables) == 0:\n",
    "        return None\n",
    "    all_tables = [\n",
    "        read_possibly_malformed_csv(\n",
    "            fragment,\n",
    "            columns=[0, 1, 2, 3, 11, 18, 24, 25, 26],\n",
    "            dtypes=[\n",
    "                pl.Int32(),\n",
    "                pl.Utf8(),\n",
    "                pl.Utf8(),\n",
    "                pl.Utf8(),\n",
    "                pl.Float64(),\n",
    "                pl.Float64(),\n",
    "                pl.Int32(),\n",
    "                pl.Float64(),\n",
    "                pl.Int32(),\n",
    "            ],\n",
    "            new_columns=[\n",
    "                \"codice_sensore\",\n",
    "                \"anno\",\n",
    "                \"mese\",\n",
    "                \"giorno\",\n",
    "                \"tmin\",\n",
    "                \"tmax\",\n",
    "                \"num_valori\",\n",
    "                \"quality\",\n",
    "                \"codice_stazione\",\n",
    "            ],\n",
    "            null_values=[\"  Dato mancante\", \"\"],\n",
    "        )\n",
    "        for fragment in available_tables\n",
    "    ]\n",
    "    return (\n",
    "        pl.concat(all_tables, how=\"vertical\")\n",
    "        .with_columns(date=pl.date(pl.col(\"anno\"), pl.col(\"mese\"), pl.col(\"giorno\")))\n",
    "        .drop([\"anno\", \"mese\", \"giorno\"])\n",
    "        .filter(pl.col(\"num_valori\").gt(0))\n",
    "    )\n",
    "\n",
    "\n",
    "for station in tqdm(stations):\n",
    "    try:\n",
    "        station_data = read_agg_fragments(station[\"code\"])\n",
    "        if station_data is not None:\n",
    "            station_data.write_parquet(base / \"dataset\" / f\"{station['code']}.parquet\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {station['code']}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
