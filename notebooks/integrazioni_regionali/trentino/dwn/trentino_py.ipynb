{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from random import uniform\n",
    "from zipfile import is_zipfile\n",
    "\n",
    "base = Path.home() / \"Local_Workspace\" / \"Datasets\" / \"ARPA\" / \"TRENTINO\" / \"trento\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat2 = pd.read_xml(base / \"meteostations2.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat2.to_csv(base / \"meta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_ids = stat2[\"codice\"].str.lower().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payload(cod_stazione, data_inizio=\"01/01/2000\", data_fine=\"01/01/2023\"):\n",
    "    return {\n",
    "        \"co\": cod_stazione,\n",
    "        \"v\": \"400.00_400.00,400.55_400.55,400.56_400.56\",\n",
    "        \"vn\": \"Temperatura aria (gradi Celsius),Temperatura aria (gradi Celsius) Min da Annale Idrologico,Temperatura aria (gradi Celsius) Max da Annale Idrologico\",\n",
    "        \"p\": \"Altro,1,1,custom,1\",\n",
    "        \"o\": \"Download,download\",\n",
    "        \"i\": \"Giornaliera,Day,1\",\n",
    "        \"cat\": \"rs\",\n",
    "        \"d1\": data_inizio,\n",
    "        \"d2\": data_fine,\n",
    "    }\n",
    "\n",
    "\n",
    "def payload_every(cod_stazione, data_inizio=\"01/01/2000\", data_fine=\"01/01/2023\"):\n",
    "    return {\n",
    "        \"co\": cod_stazione,\n",
    "        \"v\": \"400.00_400.00\",\n",
    "        \"vn\": \"Temperatura aria (gradi Celsius)\",\n",
    "        \"p\": \"Altro,1,1,custom,1\",\n",
    "        \"o\": \"Download,download\",\n",
    "        \"i\": \"Tutte le misure,Point,1\",\n",
    "        \"cat\": \"rs\",\n",
    "        \"d1\": data_inizio,\n",
    "        \"d2\": data_fine,\n",
    "    }\n",
    "\n",
    "\n",
    "base_url = \"http://storico.meteotrentino.it/cgi/webhyd.pl\"\n",
    "\n",
    "\n",
    "def download_data(\n",
    "    cod_stazione,\n",
    "    path,\n",
    "    data_inizio=\"01/01/2000\",\n",
    "    data_fine=\"01/01/2023\",\n",
    "    payload_fn=payload,\n",
    "    tout=120,\n",
    "):\n",
    "    with requests.Session() as s:\n",
    "        r = s.get(\n",
    "            base_url,\n",
    "            params=payload_fn(cod_stazione, data_inizio, data_fine),\n",
    "            timeout=tout,\n",
    "        )\n",
    "        archive_url = re.search(r\"(http://.+.zip\\?\\d+)\", r.text).group(0)\n",
    "        with s.get(archive_url, stream=True) as archive:\n",
    "            with open(path, \"wb\") as f:\n",
    "                for chunk in archive.iter_content(chunk_size=1024 * 1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "\n",
    "\n",
    "def fragment_path(cod_stazione):\n",
    "    path = base / \"fragments\" / f\"{cod_stazione}.zip\"\n",
    "    if not path.parent.exists():\n",
    "        path.parent.mkdir(parents=True)\n",
    "    return path\n",
    "\n",
    "\n",
    "def subhour_fragment_path(cod_stazione):\n",
    "    path = base / \"fragments_subhour\" / f\"{cod_stazione}.zip\"\n",
    "    if not path.parent.exists():\n",
    "        path.parent.mkdir(parents=True)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in tqdm(stat_ids):\n",
    "    path = fragment_path(sid)\n",
    "    if path.exists() and is_zipfile(path):\n",
    "        continue\n",
    "    try:\n",
    "        download_data(sid, path, \"01/01/2000\", \"01/01/2023\")\n",
    "    except:\n",
    "        print(f\"Error with {sid}. Continuing...\")\n",
    "    sleep(uniform(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_read(path):\n",
    "    stat_id = path.stem\n",
    "    data = pd.read_csv(\n",
    "        path,\n",
    "        encoding=\"iso-8859-1\",\n",
    "        skiprows=3,\n",
    "        usecols=[0, 1, 2, 3, 4, 5, 6],\n",
    "        header=0,\n",
    "        names=[\n",
    "            \"time\",\n",
    "            \"value_TAVG\",\n",
    "            \"valid_TAVG\",\n",
    "            \"value_TMIN\",\n",
    "            \"valid_TMIN\",\n",
    "            \"value_TMAX\",\n",
    "            \"valid_TMAX\",\n",
    "        ],\n",
    "    )\n",
    "    # data[\"time\"] = pd.to_datetime(data[\"time\"], format=r\"%H:%M:%S %d/%m/%Y\") #.dt.tz_localize(\"Europe/Rome\")\n",
    "    data = (\n",
    "        pl.from_pandas(\n",
    "            data,\n",
    "            schema_overrides={\n",
    "                \"time\": pl.Utf8(),\n",
    "                \"value_TAVG\": pl.Float64(),\n",
    "                \"valid_TAVG\": pl.Int32(),\n",
    "                \"value_TMIN\": pl.Float64(),\n",
    "                \"valid_TMIN\": pl.Int32(),\n",
    "                \"value_TMAX\": pl.Float64(),\n",
    "                \"valid_TMAX\": pl.Int32(),\n",
    "            },\n",
    "        ).with_columns(\n",
    "            pl.lit(stat_id).str.to_uppercase().alias(\"original_id\"),\n",
    "            pl.col(\"time\").str.to_datetime(format=r\"%H:%M:%S %d/%m/%Y\").alias(\"time\")\n",
    "        )\n",
    "        # .select(~cs.ends_with(\"TAVG\"))\n",
    "        .filter(\n",
    "            pl.col(\"value_TAVG\").is_not_null()\n",
    "            | pl.col(\"value_TMIN\").is_not_null()\n",
    "            | pl.col(\"value_TMAX\").is_not_null()\n",
    "        )\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def pl_read_subhour(path):\n",
    "    stat_id = path.stem\n",
    "    data = pd.read_csv(\n",
    "        path,\n",
    "        encoding=\"iso-8859-1\",\n",
    "        skiprows=3,\n",
    "        usecols=[0, 1, 2],\n",
    "        header=0,\n",
    "        names=[\n",
    "            \"time\",\n",
    "            \"value\",\n",
    "            \"valid\"\n",
    "        ],\n",
    "    )\n",
    "    # data[\"time\"] = pd.to_datetime(data[\"time\"], format=r\"%H:%M:%S %d/%m/%Y\") #.dt.tz_localize(\"Europe/Rome\")\n",
    "    data = (\n",
    "        pl.from_pandas(\n",
    "            data,\n",
    "            schema_overrides={\n",
    "                \"time\": pl.Utf8(),\n",
    "                \"value\": pl.Float64(),\n",
    "                \"valid\": pl.Int32(),\n",
    "            },\n",
    "        ).with_columns(\n",
    "            pl.lit(stat_id).str.to_uppercase().alias(\"original_id\"),\n",
    "            pl.col(\"time\").str.to_datetime(format=r\"%H:%M:%S %d/%m/%Y\").alias(\"time\")\n",
    "        )\n",
    "        .filter(\n",
    "            pl.col(\"value\").is_not_null() &\n",
    "            pl.col(\"valid\").lt(150)\n",
    "        )\n",
    "    )\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list((base / \"fragments\").glob(\"*.zip\"))[:1]:\n",
    "    if not is_zipfile(file):\n",
    "        print(f\"Error in {file}\")\n",
    "# pl.concat(\n",
    "#     [pl_read(file) for file in (base / \"fragments\").glob(\"*.zip\")], how=\"vertical\"\n",
    "# ).write_parquet(base / \"fragments\" / \"data.parquet\")\n",
    "data = pl.read_parquet(base / \"fragments\" / \"data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "frags = list((base / \"fragments\").glob(\"*.zip\"))\n",
    "frag = base / \"fragments_subhour\" / \"T0015.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (754_762, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>value</th><th>valid</th><th>original_id</th></tr><tr><td>datetime[Î¼s]</td><td>f64</td><td>i32</td><td>str</td></tr></thead><tbody><tr><td>2000-01-01 00:00:00</td><td>-5.8</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 01:00:00</td><td>-6.2</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 02:00:00</td><td>-6.7</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 03:00:00</td><td>-7.7</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 04:00:00</td><td>-8.3</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 05:00:00</td><td>-8.5</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 06:00:00</td><td>-9.0</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 07:00:00</td><td>-9.5</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 08:00:00</td><td>-9.5</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 09:00:00</td><td>-8.5</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 10:00:00</td><td>-7.9</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2000-01-01 11:00:00</td><td>0.9</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2022-12-31 21:15:00</td><td>3.5</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 21:30:00</td><td>3.9</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 21:45:00</td><td>3.9</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 22:00:00</td><td>3.9</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 22:15:00</td><td>3.8</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 22:30:00</td><td>3.9</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 22:45:00</td><td>3.9</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 23:00:00</td><td>3.9</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 23:15:00</td><td>4.2</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 23:30:00</td><td>4.4</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2022-12-31 23:45:00</td><td>4.5</td><td>1</td><td>&quot;T0015&quot;</td></tr><tr><td>2023-01-01 00:00:00</td><td>4.5</td><td>1</td><td>&quot;T0015&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (754_762, 4)\n",
       "âââââââââââââââââââââââ¬ââââââââ¬ââââââââ¬ââââââââââââââ\n",
       "â time                â value â valid â original_id â\n",
       "â ---                 â ---   â ---   â ---         â\n",
       "â datetime[Î¼s]        â f64   â i32   â str         â\n",
       "âââââââââââââââââââââââªââââââââªââââââââªââââââââââââââ¡\n",
       "â 2000-01-01 00:00:00 â -5.8  â 1     â T0015       â\n",
       "â 2000-01-01 01:00:00 â -6.2  â 1     â T0015       â\n",
       "â 2000-01-01 02:00:00 â -6.7  â 1     â T0015       â\n",
       "â 2000-01-01 03:00:00 â -7.7  â 1     â T0015       â\n",
       "â â¦                   â â¦     â â¦     â â¦           â\n",
       "â 2022-12-31 23:15:00 â 4.2   â 1     â T0015       â\n",
       "â 2022-12-31 23:30:00 â 4.4   â 1     â T0015       â\n",
       "â 2022-12-31 23:45:00 â 4.5   â 1     â T0015       â\n",
       "â 2023-01-01 00:00:00 â 4.5   â 1     â T0015       â\n",
       "âââââââââââââââââââââââ´ââââââââ´ââââââââ´ââââââââââââââ"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_read_subhour(frag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list((base / \"fragments_subhour\").glob(\"*.zip\")):\n",
    "    if not is_zipfile(file):\n",
    "        print(f\"Error in {file}\")\n",
    "    pl_read_subhour(file).write_parquet(base / \"fragments_subhour\" / \"dataset\" / f\"{file.stem}.parquet\")\n",
    "\n",
    "# pl.concat(\n",
    "#     [pl_read_subhour(file) for file in (base / \"fragments\").glob(\"*.zip\")], how=\"vertical\"\n",
    "# ).write_parquet(base / \"fragments\" / \"data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_redwn = (\n",
    "    data.filter(\n",
    "        (pl.col(\"value_TMIN\").is_null() & pl.col(\"value_TMAX\").is_null())\n",
    "        & pl.col(\"value_TAVG\").is_not_null()\n",
    "    )[\"original_id\"]\n",
    "    .unique()\n",
    "    .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d301895db7548f9bca9a5ce514dcfa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sid in tqdm(to_redwn):\n",
    "    path = subhour_fragment_path(sid)\n",
    "    if path.exists() and is_zipfile(path):\n",
    "        continue\n",
    "    try:\n",
    "        download_data(\n",
    "            sid, path, \"01/01/2000\", \"01/01/2023\", payload_fn=payload_every, tout=300\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {sid}: {e}. Continuing...\")\n",
    "    sleep(uniform(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
